{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f5ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36d71758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MEMBER_ID</th>\n",
       "      <th>REASONNPSSCORE__C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a2p1U000000RowfQAC</td>\n",
       "      <td>0011U00000rjFKdQAM</td>\n",
       "      <td>I showed up for my appointment, but they had m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a2p1U000000RqQqQAK</td>\n",
       "      <td>0011U00000riCSHQA2</td>\n",
       "      <td>Staff was polite, courteous, and on time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a2p1U000000RqXyQAK</td>\n",
       "      <td>0011U00000riTw7QAE</td>\n",
       "      <td>Overall care is great!  It's wonderful to be a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a2p1U000000Rq1LQAS</td>\n",
       "      <td>0011U00000rhu8eQAA</td>\n",
       "      <td>Like the doctor and staff at this location. Ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a2p1U000000RpiuQAC</td>\n",
       "      <td>0011U00000rk4SHQAY</td>\n",
       "      <td>The convenience and the doctors</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID           MEMBER_ID  \\\n",
       "0  a2p1U000000RowfQAC  0011U00000rjFKdQAM   \n",
       "1  a2p1U000000RqQqQAK  0011U00000riCSHQA2   \n",
       "2  a2p1U000000RqXyQAK  0011U00000riTw7QAE   \n",
       "3  a2p1U000000Rq1LQAS  0011U00000rhu8eQAA   \n",
       "4  a2p1U000000RpiuQAC  0011U00000rk4SHQAY   \n",
       "\n",
       "                                   REASONNPSSCORE__C  \n",
       "0  I showed up for my appointment, but they had m...  \n",
       "1           Staff was polite, courteous, and on time  \n",
       "2  Overall care is great!  It's wonderful to be a...  \n",
       "3  Like the doctor and staff at this location. Ea...  \n",
       "4                    The convenience and the doctors  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Dataset - NLP Assignment.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a5f69ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['ID','MEMBER_ID'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1969486f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REASONNPSSCORE__C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I showed up for my appointment, but they had m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Staff was polite, courteous, and on time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overall care is great!  It's wonderful to be a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Like the doctor and staff at this location. Ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The convenience and the doctors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3807</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3808</th>\n",
       "      <td>Very skeptical that you will soon be without a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3809</th>\n",
       "      <td>Doctor Malfese is easily accessible, staff is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3810</th>\n",
       "      <td>Friendly Staff that can be reached at any time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3811</th>\n",
       "      <td>This was without a doubt the worst example of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3812 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      REASONNPSSCORE__C\n",
       "0     I showed up for my appointment, but they had m...\n",
       "1              Staff was polite, courteous, and on time\n",
       "2     Overall care is great!  It's wonderful to be a...\n",
       "3     Like the doctor and staff at this location. Ea...\n",
       "4                       The convenience and the doctors\n",
       "...                                                 ...\n",
       "3807                                                yes\n",
       "3808  Very skeptical that you will soon be without a...\n",
       "3809  Doctor Malfese is easily accessible, staff is ...\n",
       "3810     Friendly Staff that can be reached at any time\n",
       "3811  This was without a doubt the worst example of ...\n",
       "\n",
       "[3812 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96f64177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REASONNPSSCORE__C    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea875a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['REASONNPSSCORE__C'] = data['REASONNPSSCORE__C'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72b90f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REASONNPSSCORE__C    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab22389b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i showed up for my appointment but they had me...\n",
       "1               staff was polite courteous and on time\n",
       "2    overall care is great  it's wonderful to be ab...\n",
       "3    like the doctor and staff at this location eas...\n",
       "4                      the convenience and the doctors\n",
       "Name: REASONNPSSCORE__C, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the regular expression library\n",
    "import re\n",
    "\n",
    "# Remove punctuation\n",
    "data['REASONNPSSCORE__C'] = data['REASONNPSSCORE__C'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "\n",
    "# Convert the titles to lowercase\n",
    "data['REASONNPSSCORE__C'] = data['REASONNPSSCORE__C'].map(lambda x: x.lower())\n",
    "\n",
    "# Print out the first rows of papers\n",
    "data['REASONNPSSCORE__C'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "544d57ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gensim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-78774dab9073>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Build the bigram and trigram models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbigram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPhrases\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# higher threshold fewer phrases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrigram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPhrases\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbigram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_words\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Faster way to get a sentence clubbed as a trigram/bigram\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gensim' is not defined"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2832e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31808135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (1.0.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (8.0.17)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (4.59.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (0.6.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.4.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (52.0.0.post20210125)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (0.7.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (1.22.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.7.4.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be5098b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.3.0) (3.3.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (21.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.17)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.59.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.25.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.22.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.11.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.7)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.7.4.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.26.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.1.1)\n",
      "âš  As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the full\n",
      "pipeline package name 'en_core_web_sm' instead.\n",
      "âœ” Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-16 09:42:24.868492: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-06-16 09:42:24.869066: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e80bdf2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_lemmatized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-602175ad452c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_lemmatized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data_lemmatized' is not defined"
     ]
    }
   ],
   "source": [
    "data_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b48d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import  Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dec63af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lemmatized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bcdd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import  Counter\n",
    "\n",
    "def plot_top_ngrams_barchart(text, n=2):\n",
    "    stop=set(stopwords.words('english'))\n",
    "\n",
    "    new= text.str.split()\n",
    "    new=new.values.tolist()\n",
    "    corpus=[word for i in new for word in i]\n",
    "\n",
    "    def _get_top_ngram(corpus, n=None):\n",
    "        vec = CountVectorizer(ngram_range=(n, n)).fit(corpus)\n",
    "        bag_of_words = vec.transform(corpus)\n",
    "        sum_words = bag_of_words.sum(axis=0) \n",
    "        words_freq = [(word, sum_words[0, idx]) \n",
    "                      for word, idx in vec.vocabulary_.items()]\n",
    "        words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "        return words_freq[:20]\n",
    "\n",
    "    top_n_bigrams=_get_top_ngram(text,n)[:20]\n",
    "    x,y=map(list,zip(*top_n_bigrams))\n",
    "    sns.barplot(x=y,y=x)\n",
    "\n",
    "plot_top_ngrams_barchart(data['REASONNPSSCORE__C'],3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776db714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_lem = pd.DataFrame(data_lemmatized) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c7b34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8afd3f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_top_ngram(corpus, n=None):\n",
    "        vec = CountVectorizer(ngram_range=(n, n)).fit(corpus)\n",
    "        bag_of_words = vec.transform(corpus)\n",
    "        sum_words = bag_of_words.sum(axis=0) \n",
    "        words_freq = [(word, sum_words[0, idx]) \n",
    "                      for word, idx in vec.vocabulary_.items()]\n",
    "        words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "        return words_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75fd7d9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CountVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-0b639aa26a60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtri_gram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_top_ngram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'REASONNPSSCORE__C'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mword_tri\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtri_gram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mword_tri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtri_gram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-465114297970>\u001b[0m in \u001b[0;36m_get_top_ngram\u001b[1;34m(corpus, n)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_get_top_ngram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m         \u001b[0mvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mbag_of_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0msum_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbag_of_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         words_freq = [(word, sum_words[0, idx]) \n",
      "\u001b[1;31mNameError\u001b[0m: name 'CountVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "tri_gram = _get_top_ngram(data['REASONNPSSCORE__C'],3)\n",
    "word_tri = []\n",
    "for i in range(len(tri_gram)):\n",
    "    word_tri.append(tri_gram[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4c41568b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['easy to get',\n",
       " 'to get in',\n",
       " 'to get an',\n",
       " 'get an appointment',\n",
       " 'the doctor was',\n",
       " 'very friendly and',\n",
       " 'able to get',\n",
       " 'the time to',\n",
       " 'with the doctor',\n",
       " 'easy to schedule',\n",
       " 'was able to',\n",
       " 'the staff is',\n",
       " 'the staff was',\n",
       " 'and the staff',\n",
       " 'to be seen',\n",
       " 'an appointment and',\n",
       " 'to go to',\n",
       " 'in and out',\n",
       " 'to see the',\n",
       " 'and the doctor',\n",
       " 'to talk to',\n",
       " 'time to listen',\n",
       " 'the doctor and',\n",
       " 'did not have',\n",
       " 'easy to make',\n",
       " 'make an appointment',\n",
       " 'in the office',\n",
       " 'had to wait',\n",
       " 'have to wait',\n",
       " 'my first visit',\n",
       " 'to make an',\n",
       " 'very nice and',\n",
       " 'be able to',\n",
       " 'was my first',\n",
       " 'was very nice',\n",
       " 'was very friendly',\n",
       " 'staff is very',\n",
       " 'and easy to',\n",
       " 'the doctor is',\n",
       " 'see the doctor',\n",
       " 'doctor was very',\n",
       " 'like the doctor',\n",
       " 'time with you',\n",
       " 'my primary care',\n",
       " 'friendly and helpful',\n",
       " 'staff was very',\n",
       " 'one on one',\n",
       " 'to get to',\n",
       " 'with me and',\n",
       " 'to the doctor',\n",
       " 'my doctor is',\n",
       " 'time with me',\n",
       " 'to schedule an',\n",
       " 'get in to',\n",
       " 'great service and',\n",
       " 'in timely manner',\n",
       " 'for an appointment',\n",
       " 'amount of time',\n",
       " 'took time to',\n",
       " 'and did not',\n",
       " 'in to see',\n",
       " 'this was my',\n",
       " 'the same day',\n",
       " 'it is convenient',\n",
       " 'took the time',\n",
       " 'there is no',\n",
       " 'only had one',\n",
       " 'the front desk',\n",
       " 'hard to get',\n",
       " 'the first time',\n",
       " 'was friendly and',\n",
       " 'to get me',\n",
       " 'made me feel',\n",
       " 'all of my',\n",
       " 'have to go',\n",
       " 'the appointment was',\n",
       " 'like my doctor',\n",
       " 'quick and easy',\n",
       " 'very easy to',\n",
       " 'easy to talk',\n",
       " 'schedule an appointment',\n",
       " 'is easy to',\n",
       " 'my appointment was',\n",
       " 'don have to',\n",
       " 'for me to',\n",
       " 'my doctor and',\n",
       " 'was easy to',\n",
       " 'was very thorough',\n",
       " 'friendly staff and',\n",
       " 'and it was',\n",
       " 'to be able',\n",
       " 'the convenience of',\n",
       " 'it would be',\n",
       " 'time to get',\n",
       " 'to make appointments',\n",
       " 'very helpful and',\n",
       " 'is friendly and',\n",
       " 'it is easy',\n",
       " 'had one visit',\n",
       " 'with my doctor',\n",
       " 'it has been',\n",
       " 'to listen to',\n",
       " 'need to be',\n",
       " 'time spent with',\n",
       " 'ease of access',\n",
       " 'difficult to get',\n",
       " 'it was easy',\n",
       " 'to know me',\n",
       " 'all my questions',\n",
       " 'it was my',\n",
       " 'over the phone',\n",
       " 'the doctors and',\n",
       " 'get to know',\n",
       " 'the office staff',\n",
       " 'was supposed to',\n",
       " 'really like the',\n",
       " 'that the doctor',\n",
       " 'is convenient and',\n",
       " 'staff is friendly',\n",
       " 'very pleased with',\n",
       " 'so far so',\n",
       " 'and was told',\n",
       " 'there was no',\n",
       " 'take the time',\n",
       " 'in the waiting',\n",
       " 'the waiting room',\n",
       " 'to get my',\n",
       " 'and had to',\n",
       " 'same day appointment',\n",
       " 'the one on',\n",
       " 'experience with xyz',\n",
       " 'great customer service',\n",
       " 'can get in',\n",
       " 'doctor and the',\n",
       " 'no co pay',\n",
       " 'to get appointment',\n",
       " 'the fact that',\n",
       " 'get in and',\n",
       " 'far so good',\n",
       " 'was told that',\n",
       " 'is very nice',\n",
       " 'of the office',\n",
       " 'to get appointments',\n",
       " 'to call back',\n",
       " 'happy with the',\n",
       " 'not have the',\n",
       " 'out of pocket',\n",
       " 'very professional and',\n",
       " 'was told to',\n",
       " 'because of the',\n",
       " 'and friendly service',\n",
       " 'to deal with',\n",
       " 'the exam room',\n",
       " 'no wait time',\n",
       " 'it was very',\n",
       " 'get me in',\n",
       " 'seem to be',\n",
       " 'the office and',\n",
       " 'take their time',\n",
       " 'staff was friendly',\n",
       " 'doctor and staff',\n",
       " 'like the convenience',\n",
       " 'get in for',\n",
       " 'the doctor took',\n",
       " 'the level of',\n",
       " 'it was good',\n",
       " 'the doctor saw',\n",
       " 'the ability to',\n",
       " 'to see doctor',\n",
       " 'appointment and the',\n",
       " 'staff and doctor',\n",
       " 'pleased with the',\n",
       " 'seems to be',\n",
       " 'the office is',\n",
       " 'listen to me',\n",
       " 'access to the',\n",
       " 'to work with',\n",
       " 'with the service',\n",
       " 'dr was very',\n",
       " 'is very convenient',\n",
       " 'doctor did not',\n",
       " 'being able to',\n",
       " 'was quick and',\n",
       " 'very thorough and',\n",
       " 'my last visit',\n",
       " 'the next day',\n",
       " 'had to go',\n",
       " 'to me and',\n",
       " 'time to talk',\n",
       " 'on the phone',\n",
       " 'quality of care',\n",
       " 'do not have',\n",
       " 'takes the time',\n",
       " 'to my concerns',\n",
       " 'primary care doctor',\n",
       " 'they did not',\n",
       " 'time with the',\n",
       " 'of the staff',\n",
       " 'the amount of',\n",
       " 'access to doctor',\n",
       " 'plenty of time',\n",
       " 'of time to',\n",
       " 'listened to my',\n",
       " 'the new doctor',\n",
       " 'to the office',\n",
       " 'friendly and professional',\n",
       " 'feel like the',\n",
       " 'doctors and staff',\n",
       " 'and staff are',\n",
       " 'are friendly and',\n",
       " 'and it is',\n",
       " 'in the past',\n",
       " 'ease of scheduling',\n",
       " 'as well as',\n",
       " 'had to call',\n",
       " 'my concerns and',\n",
       " 'it is very',\n",
       " 'was in the',\n",
       " 'the office was',\n",
       " 'the doctors are',\n",
       " 'about my health',\n",
       " 'did not feel',\n",
       " 'of my friends',\n",
       " 'it hard to',\n",
       " 'going on with',\n",
       " 'of the doctors',\n",
       " 'friendly and knowledgeable',\n",
       " 'waste of time',\n",
       " 'the doctor did',\n",
       " 'the only reason',\n",
       " 'most of the',\n",
       " 'they were very',\n",
       " 'go to xyz',\n",
       " 'listen to my',\n",
       " 'been able to',\n",
       " 'most of my',\n",
       " 'to see how',\n",
       " 'able to spend',\n",
       " 'were able to',\n",
       " 'close to work',\n",
       " 'in for an',\n",
       " 'impressed with the',\n",
       " 'the ease of',\n",
       " 'the doctor that',\n",
       " 'of time with',\n",
       " 'the clinic is',\n",
       " 'recommend xyz to',\n",
       " 'due to the',\n",
       " 'is very personable',\n",
       " 'you have to',\n",
       " 'to draw blood',\n",
       " 'have only had',\n",
       " 'staff are friendly',\n",
       " 'and friendly staff',\n",
       " 'is very friendly',\n",
       " 'would like to',\n",
       " 'seem to care',\n",
       " 'to care about',\n",
       " 'take time to',\n",
       " 'for them to',\n",
       " 'time to explain',\n",
       " 'easy to access',\n",
       " 'out of the',\n",
       " 'me feel like',\n",
       " 'do not feel',\n",
       " 'did not seem',\n",
       " 'trying to get',\n",
       " 'not have to',\n",
       " 'into the office',\n",
       " 'primary care physician',\n",
       " 'very convenient and',\n",
       " 'an appointment was',\n",
       " 'on time and',\n",
       " 'in to the',\n",
       " 'the staff and',\n",
       " 'it is not',\n",
       " 'would have to',\n",
       " 'my health and',\n",
       " 'you need to',\n",
       " 'they take their',\n",
       " 'with you and',\n",
       " 'to see if',\n",
       " 'it was convenient',\n",
       " 'very kind and',\n",
       " 'to listen and',\n",
       " 'wait time was',\n",
       " 'and that is',\n",
       " 'went in for',\n",
       " 'seemed to be',\n",
       " 'for my appointment',\n",
       " 'and on time',\n",
       " 'they are very',\n",
       " 'they were able',\n",
       " 'didn have to',\n",
       " 'you can get',\n",
       " 'like the staff',\n",
       " 'to call and',\n",
       " 'get same day',\n",
       " 'easy to use',\n",
       " 'the lack of',\n",
       " 'was very helpful',\n",
       " 'the dr and',\n",
       " 'the appointment and',\n",
       " 'to wait long',\n",
       " 'very personable and',\n",
       " 'all the time',\n",
       " 'is no longer',\n",
       " 'to get into',\n",
       " 'like the concept',\n",
       " 'so don have',\n",
       " 'takes time to',\n",
       " 'some of the',\n",
       " 'this is the',\n",
       " 'have access to',\n",
       " 'all of the',\n",
       " 'doctors and nurses',\n",
       " 'very hard to',\n",
       " 'an appointment the',\n",
       " 'needed to see',\n",
       " 'go to the',\n",
       " 'to come back',\n",
       " 'very knowledgeable and',\n",
       " 'to get the',\n",
       " 'staff and doctors',\n",
       " 'get an appt',\n",
       " 'don feel rushed',\n",
       " 'out of my',\n",
       " 'is not very',\n",
       " 'makes me feel',\n",
       " 'convenient for me',\n",
       " 'takes her time',\n",
       " 'didn feel rushed',\n",
       " 'able to see',\n",
       " 'and gave me',\n",
       " 'back to me',\n",
       " 'good customer service',\n",
       " 'convenient and the',\n",
       " 'me and my',\n",
       " 'to the clinic',\n",
       " 'very friendly staff',\n",
       " 'and time spent',\n",
       " 'good service and',\n",
       " 'one of the',\n",
       " 'don know if',\n",
       " 'my doctor was',\n",
       " 'in the same',\n",
       " 'and listened to',\n",
       " 'spent with me',\n",
       " 'the nurse practitioner',\n",
       " 'felt like was',\n",
       " 'too early to',\n",
       " 'easy access to',\n",
       " 'want to see',\n",
       " 'to make sure',\n",
       " 'go back to',\n",
       " 'and the office',\n",
       " 'was sick and',\n",
       " 'to help me',\n",
       " 'it is good',\n",
       " 'the doctor but',\n",
       " 'appointment was at',\n",
       " 'and she was',\n",
       " 'do not know',\n",
       " 'take care of',\n",
       " 'for an appt',\n",
       " 'to get same',\n",
       " 'if you are',\n",
       " 'and the time',\n",
       " 'their time to',\n",
       " 'would not recommend',\n",
       " 'friendly service and',\n",
       " 'for the doctor',\n",
       " 'and nurse were',\n",
       " 'convenient and easy',\n",
       " 'when you are',\n",
       " 'having to wait',\n",
       " 'ease of appointments',\n",
       " 'to talk with',\n",
       " 'to find out',\n",
       " 'because it is',\n",
       " 'at the front',\n",
       " 'able to be',\n",
       " 'but so far',\n",
       " 'needed to be',\n",
       " 'that it is',\n",
       " 'was very good',\n",
       " 'we were told',\n",
       " 'to wait for',\n",
       " 'to be there',\n",
       " 'they seem to',\n",
       " 'did not like',\n",
       " 'my well being',\n",
       " 'were friendly and',\n",
       " 'since it was',\n",
       " 'my first experience',\n",
       " 'came in for',\n",
       " 'to have to',\n",
       " 'the service and',\n",
       " 'the service is',\n",
       " 'not happy with',\n",
       " 'are very helpful',\n",
       " 'have an appointment',\n",
       " 'to the point',\n",
       " 'to see me',\n",
       " 'not seem to',\n",
       " 'and the nurse',\n",
       " 'did not know',\n",
       " 'know me and',\n",
       " 'is going on',\n",
       " 'and listen to',\n",
       " 'very happy with',\n",
       " 'the office for',\n",
       " 'the blood draw',\n",
       " 'not very convenient',\n",
       " 'was not given',\n",
       " 'and was not',\n",
       " 'more time with',\n",
       " 'always friendly and',\n",
       " 'get in quickly',\n",
       " 'on short notice',\n",
       " 'in the room',\n",
       " 'like that the',\n",
       " 'staff and the',\n",
       " 'their time with',\n",
       " 'at the office',\n",
       " 'were very nice',\n",
       " 'blood work done',\n",
       " 'supposed to be',\n",
       " 'love my doctor',\n",
       " 'had great experience',\n",
       " 'to be very',\n",
       " 'doctor is very',\n",
       " 'was going to',\n",
       " 'the service was',\n",
       " 'very attentive and',\n",
       " 'me feel comfortable',\n",
       " 'doctor is not',\n",
       " 'going to be',\n",
       " 'lot of time',\n",
       " 'the staff were',\n",
       " 'like the dr',\n",
       " 'was there for',\n",
       " 'was told would',\n",
       " 'feel like they',\n",
       " 'don feel like',\n",
       " 'like the idea',\n",
       " 'the idea of',\n",
       " 'it was great',\n",
       " 'and was able',\n",
       " 'is the best',\n",
       " 'the next morning',\n",
       " 'get back to',\n",
       " 'the wait time',\n",
       " 'it easy to',\n",
       " 'spends time with',\n",
       " 'was good experience',\n",
       " 'my first time',\n",
       " 'waiting in the',\n",
       " 'to tell me',\n",
       " 'have never had',\n",
       " 'felt like the',\n",
       " 'in the future',\n",
       " 'they told me',\n",
       " 'now have to',\n",
       " 'told me to',\n",
       " 'the concept of',\n",
       " 'is nice and',\n",
       " 'and felt like',\n",
       " 'not able to',\n",
       " 'as soon as',\n",
       " 'answered all my',\n",
       " 'visit the doctor',\n",
       " 'the convenience and',\n",
       " 'and they were',\n",
       " 'by the doctor',\n",
       " 'experience so far',\n",
       " 'and like the',\n",
       " 'feel like my',\n",
       " 'very impressed with',\n",
       " 'they said they',\n",
       " 'and they did',\n",
       " 'called me back',\n",
       " 'to the pharmacy',\n",
       " 'doctor took time',\n",
       " 'my health history',\n",
       " 'the time that',\n",
       " 'quality time with',\n",
       " 'to the patient',\n",
       " 'staff have been',\n",
       " 'my medical history',\n",
       " 'time to answer',\n",
       " 'pleased with my',\n",
       " 'she was very',\n",
       " 'be seen by',\n",
       " 'everyone was very',\n",
       " 'helpful and friendly',\n",
       " 'back and forth',\n",
       " 'with the doctors',\n",
       " 'the following day',\n",
       " 'talk to and',\n",
       " 'of xyz and',\n",
       " 'for the appointment',\n",
       " 'in the clinic',\n",
       " 'easy and convenient',\n",
       " 'like my dr',\n",
       " 'friendly and the',\n",
       " 'and they didn',\n",
       " 'was very pleased',\n",
       " 'was great and',\n",
       " 'she was not',\n",
       " 'when am sick',\n",
       " 'to see someone',\n",
       " 'staff were very',\n",
       " 'of scheduling and',\n",
       " 'the online portal',\n",
       " 'was not as',\n",
       " 'like that it',\n",
       " 'with me to',\n",
       " 'that is not',\n",
       " 'ease of making',\n",
       " 'customer service and',\n",
       " 'see the dr',\n",
       " 'my experience was',\n",
       " 'if they were',\n",
       " 'spent with patient',\n",
       " 'the nurse was',\n",
       " 'we don have',\n",
       " 'don have time',\n",
       " 'care about your',\n",
       " 'didn feel like',\n",
       " 'to get hold',\n",
       " 'get hold of',\n",
       " 'at the clinic',\n",
       " 'nice and helpful',\n",
       " 'if you need',\n",
       " 'during my visit',\n",
       " 'service and the',\n",
       " 'due to my',\n",
       " 'like the personal',\n",
       " 'to go in',\n",
       " 'ability to get',\n",
       " 'to my doctor',\n",
       " 'would recommend this',\n",
       " 'never feel rushed',\n",
       " 'really liked the',\n",
       " 'you are not',\n",
       " 'you do not',\n",
       " 'hard to find',\n",
       " 'not in my',\n",
       " 'can recommend to',\n",
       " 'great but the',\n",
       " 'to figure out',\n",
       " 'what is going',\n",
       " 'listen to you',\n",
       " 'it very convenient',\n",
       " 'and very professional',\n",
       " 'it was quick',\n",
       " 'like the fact',\n",
       " 'it convenient and',\n",
       " 'have been to',\n",
       " 'the front office',\n",
       " 'talk to someone',\n",
       " 'make you feel',\n",
       " 'to go back',\n",
       " 'in the exam',\n",
       " 'have had to',\n",
       " 'and convenient location',\n",
       " 'of time the',\n",
       " 'refer me to',\n",
       " 'nice to be',\n",
       " 've ever had',\n",
       " 'last visit was',\n",
       " 'don know enough',\n",
       " 'doctor and nurse',\n",
       " 'that the staff',\n",
       " 'was happy with',\n",
       " 'on time appointments',\n",
       " 'long wait time',\n",
       " 'everyone is nice',\n",
       " 'but the office',\n",
       " 'my appointment and',\n",
       " 'the facility was',\n",
       " 'my blood work',\n",
       " 'have only been',\n",
       " 'time to understand',\n",
       " 'follow up and',\n",
       " 'getting an appointment',\n",
       " 'it was nice',\n",
       " 'the people are',\n",
       " 'fast and friendly',\n",
       " 'was nice and',\n",
       " 'nice and professional',\n",
       " 'when the doctor',\n",
       " 'after my appointment',\n",
       " 'xyz health and',\n",
       " 'answer the phone',\n",
       " 'doctor was not',\n",
       " 'and made me',\n",
       " 'appointment in timely',\n",
       " 'feel that the',\n",
       " 'would have been',\n",
       " 'work with the',\n",
       " 'availability of the',\n",
       " 'and they take',\n",
       " 'was very rude',\n",
       " 'took her time',\n",
       " 'was fast and',\n",
       " 'not sure how',\n",
       " 'very pleasant and',\n",
       " 'has been great',\n",
       " 'to get blood',\n",
       " 'wait time and',\n",
       " 'for people who',\n",
       " 'and in the',\n",
       " 'to pay for',\n",
       " 'dr and staff',\n",
       " 'used to be',\n",
       " 'am able to',\n",
       " 'able to schedule',\n",
       " 'quick to get',\n",
       " 'little to no',\n",
       " 'and quality of',\n",
       " 'part of the',\n",
       " 'able to make',\n",
       " 'the doctors office',\n",
       " 'of the clinic',\n",
       " 'taken care of',\n",
       " 'have to leave',\n",
       " 'have to call',\n",
       " 'with the nurse',\n",
       " 'ease of getting',\n",
       " 'it is difficult',\n",
       " 'is difficult to',\n",
       " 'the doctors take',\n",
       " 'the office to',\n",
       " 'will not be',\n",
       " 'to schedule appointments',\n",
       " 'my blood drawn',\n",
       " 'if it is',\n",
       " 'waiting to see',\n",
       " 'my questions were',\n",
       " 'questions were answered',\n",
       " 'was unable to',\n",
       " 'get in touch',\n",
       " 'appointment was very',\n",
       " 'are very friendly',\n",
       " 'and caring staff',\n",
       " 'my experience with',\n",
       " 'of xyz health',\n",
       " 'they didn have',\n",
       " 'get call back',\n",
       " 'and don have',\n",
       " 'didn have the',\n",
       " 'this is my',\n",
       " 'so far it',\n",
       " 'for me and',\n",
       " 'get my blood',\n",
       " 'to me when',\n",
       " 'not having to',\n",
       " 'to help with',\n",
       " 'call me back',\n",
       " 'soon as possible',\n",
       " 'my current pcp',\n",
       " 'to meet with',\n",
       " 'extremely friendly and',\n",
       " 'convenience of the',\n",
       " 'of the location',\n",
       " 'go to another',\n",
       " 'dr spends time',\n",
       " 'enough experience with',\n",
       " 'with xyz to',\n",
       " 'would be 10',\n",
       " 'of my time',\n",
       " 'to do with',\n",
       " 'liked the doctor',\n",
       " 'nice to have',\n",
       " 'an in person',\n",
       " 'it is great',\n",
       " 'they called me',\n",
       " 'told me they',\n",
       " 'have to make',\n",
       " 'it seems like',\n",
       " 'good amount of',\n",
       " 'health history and',\n",
       " 'really liked dr',\n",
       " 'the time they',\n",
       " 'to spend with',\n",
       " 'that did not',\n",
       " 'and have had',\n",
       " 'level of service',\n",
       " 'quick access to',\n",
       " 'answer my questions',\n",
       " 'ease of use',\n",
       " 'listened to and',\n",
       " 'more time to',\n",
       " 'what have experienced',\n",
       " 'time to discuss',\n",
       " 'was pleased with',\n",
       " 'was thorough and',\n",
       " 'and was very',\n",
       " 'like the time',\n",
       " 'time that the',\n",
       " 'me and the',\n",
       " 'my test results',\n",
       " 'the medical assistant',\n",
       " 'like we were',\n",
       " 'and ended up',\n",
       " 'ended up in',\n",
       " 'wanted me to',\n",
       " 'at 11 30',\n",
       " 'is very knowledgeable',\n",
       " 'an appointment quickly',\n",
       " 'was knowledgeable and',\n",
       " 'the second time',\n",
       " 'no long wait',\n",
       " 'you are sick',\n",
       " 'have to do',\n",
       " 'interested in me',\n",
       " 'have been very',\n",
       " 'been very pleased',\n",
       " 'scheduling an appointment',\n",
       " 'was the only',\n",
       " 'the only one',\n",
       " 'and convenient to',\n",
       " 'feel like get',\n",
       " 'and there is',\n",
       " 'to call in',\n",
       " 'to me about',\n",
       " 'the time needed',\n",
       " 'appointment with my',\n",
       " 'like the one',\n",
       " 'the rest of',\n",
       " 'rest of the',\n",
       " 'front desk was',\n",
       " 'schedule an appt',\n",
       " 'he listened to',\n",
       " 'had to say',\n",
       " 'were very friendly',\n",
       " 'very welcoming and',\n",
       " 'the process of',\n",
       " 'does not have',\n",
       " 'visit was very',\n",
       " 'it was not',\n",
       " 'the time he',\n",
       " 'to talk about',\n",
       " 'it is to',\n",
       " 'the doctor the',\n",
       " 'that they have',\n",
       " 'got me in',\n",
       " 'had sinus infection',\n",
       " 'there is little',\n",
       " 'weeks to get',\n",
       " 'with my provider',\n",
       " 'go to urgent',\n",
       " 'to urgent care',\n",
       " 'time to see',\n",
       " 'easy to work',\n",
       " 'figure out how',\n",
       " 'me to come',\n",
       " 'then had to',\n",
       " 'the doctor to',\n",
       " 'have time to',\n",
       " 'about your health',\n",
       " 'of my concerns',\n",
       " 'one visit and',\n",
       " 'that have been',\n",
       " 'the day before',\n",
       " 'to be called',\n",
       " 'be called in',\n",
       " 'call back and',\n",
       " 'for sinus infection',\n",
       " 'sinus infection and',\n",
       " 'time with doctor',\n",
       " 'are very nice',\n",
       " 'very attentive to',\n",
       " 'convenient location for',\n",
       " 'interest in my',\n",
       " 'to your concerns',\n",
       " 'very difficult to',\n",
       " 'the doctor spent',\n",
       " 'not listen to',\n",
       " 'he told me',\n",
       " 'would only recommend',\n",
       " 'that they were',\n",
       " 'the doctor seemed',\n",
       " 'my health she',\n",
       " 'her time with',\n",
       " 'and they are',\n",
       " 'up to the',\n",
       " 'that there is',\n",
       " 'not feel rushed',\n",
       " 'is great and',\n",
       " 'feel rushed and',\n",
       " 'doctor was thorough',\n",
       " 'may not have',\n",
       " 'always have to',\n",
       " 'the dr was',\n",
       " 'patient and thorough',\n",
       " 'not sure about',\n",
       " 'to use my',\n",
       " 'over an hour',\n",
       " 'that xyz is',\n",
       " 'think it is',\n",
       " 'for the first',\n",
       " 'fast and efficient',\n",
       " 'is great but',\n",
       " 'the location is',\n",
       " 'told to go',\n",
       " 'in order to',\n",
       " 'figure out what',\n",
       " 'happy with dr',\n",
       " 'me with the',\n",
       " 'other than that',\n",
       " 'was very convenient',\n",
       " 'follow up with',\n",
       " 'and does not',\n",
       " 'too much time',\n",
       " 'care of me',\n",
       " 'very good and',\n",
       " 'my friends and',\n",
       " 'locations are not',\n",
       " 'staff is nice',\n",
       " 'willing to help',\n",
       " 'what was going',\n",
       " 'was going on',\n",
       " 'but was not',\n",
       " 'first visit so',\n",
       " 'time with dr',\n",
       " 'to follow up',\n",
       " 'as long as',\n",
       " 'let me know',\n",
       " 'interaction with the',\n",
       " 'give it 10',\n",
       " 'not feeling rushed',\n",
       " 'thorough and very',\n",
       " 'time the doctor',\n",
       " 'with the patient',\n",
       " 'to refer me',\n",
       " 'was very unprofessional',\n",
       " 'the need to',\n",
       " 'no waiting time',\n",
       " 'spend time with',\n",
       " 'you instead of',\n",
       " 'of the time',\n",
       " 'made the appointment',\n",
       " 'the appointment for',\n",
       " 'seem very professional',\n",
       " 'dr song was',\n",
       " 'like that can',\n",
       " 'and that the',\n",
       " 'that the doctors',\n",
       " 'for flu shot',\n",
       " 'the staff at',\n",
       " 'needs to be',\n",
       " 'my co workers',\n",
       " 'was really nice',\n",
       " 'really nice and',\n",
       " 'recommend doctors to',\n",
       " 'to my friends',\n",
       " 'would recommend xyz',\n",
       " 'to wait to',\n",
       " 'the office the',\n",
       " 'did not get',\n",
       " 'was very personable',\n",
       " 'the patient portal',\n",
       " 'going to the',\n",
       " 'but the doctor',\n",
       " 'is leaving and',\n",
       " 'to the dr',\n",
       " 'cost to me',\n",
       " 'very good service',\n",
       " 'of the doctor',\n",
       " 'have to be',\n",
       " 'have to take',\n",
       " 'is the same',\n",
       " 'and not very',\n",
       " 'was very disappointed',\n",
       " 'with my care',\n",
       " 'quick and convenient',\n",
       " 've only had',\n",
       " 'and the people',\n",
       " 'when came in',\n",
       " 'the doctor came',\n",
       " 'doctor came in',\n",
       " 'need to see',\n",
       " 'the day of',\n",
       " 'does not seem',\n",
       " 'part of my',\n",
       " 'and helpful staff',\n",
       " 'with xyz health',\n",
       " 'to come to',\n",
       " 'by my employer',\n",
       " 'after the appointment',\n",
       " 'my primary doctor',\n",
       " 'willing to listen',\n",
       " 'over the counter',\n",
       " 'they are not',\n",
       " 'first visit and',\n",
       " 'no one was',\n",
       " 'to my needs',\n",
       " 'not feel that',\n",
       " 'spent lot of',\n",
       " 'recommend it to',\n",
       " 'do not work',\n",
       " 'recommend to my',\n",
       " 'in one place',\n",
       " 'didn feel comfortable',\n",
       " 'with my health',\n",
       " 'that was not',\n",
       " 'which did not',\n",
       " 'that would have',\n",
       " 'you feel like',\n",
       " 'up going to',\n",
       " 'to have my',\n",
       " 'in the next',\n",
       " 'and not rushed',\n",
       " 'xyz and dr',\n",
       " 'my visit was',\n",
       " 'at the same',\n",
       " 'and dr was',\n",
       " 'spent with the',\n",
       " 'talk to me',\n",
       " 'her time to',\n",
       " 'and takes the',\n",
       " 'was very pleasant',\n",
       " 'friendly and very',\n",
       " 'like being able',\n",
       " 'care about me',\n",
       " 'me as person',\n",
       " 'had already been',\n",
       " 'and have been',\n",
       " 'called for an',\n",
       " 'was told it',\n",
       " 'relationship with my',\n",
       " 'to come in',\n",
       " 'in for my',\n",
       " 'come in and',\n",
       " 'it seems as',\n",
       " 'seems as though',\n",
       " 'very responsive and',\n",
       " 'staff was great',\n",
       " 'and they don',\n",
       " 'to make it',\n",
       " 'could be better',\n",
       " 'have confidence in',\n",
       " 'satisfied with the',\n",
       " 'with the dr',\n",
       " 'visit with the',\n",
       " 'to my home',\n",
       " 'face to face',\n",
       " 'one way or',\n",
       " 'friendly and fast',\n",
       " 'up by the',\n",
       " 'is not the',\n",
       " 'it was an',\n",
       " 'nice staff and',\n",
       " 'if you have',\n",
       " 'can go to',\n",
       " 'staff are very',\n",
       " 'and there was',\n",
       " 'to the nurse',\n",
       " 'the nurse to',\n",
       " 'to call me',\n",
       " 'me to get',\n",
       " 'will have to',\n",
       " 'the care receive',\n",
       " 'to answer questions',\n",
       " 'had to ask',\n",
       " 'and good service',\n",
       " 'of getting an',\n",
       " 'and have not',\n",
       " 'thorough and friendly',\n",
       " 'of my needs',\n",
       " 'no waiting in',\n",
       " 'the results of',\n",
       " 'deal of time',\n",
       " 'at the time',\n",
       " 'the time of',\n",
       " 'for follow up',\n",
       " 'have not heard',\n",
       " 'it for the',\n",
       " 'the nurse and',\n",
       " 'have to use',\n",
       " 'to go elsewhere',\n",
       " 'this type of',\n",
       " 'to give me',\n",
       " 'recommend to anyone',\n",
       " 'to see my',\n",
       " 'fast and easy',\n",
       " 'talk to you',\n",
       " 'service was good',\n",
       " 'in touch with',\n",
       " 'her time and',\n",
       " 'dr is very',\n",
       " 'the quality of',\n",
       " 'but am not',\n",
       " 'me to be',\n",
       " 'to see her',\n",
       " 'had good experience',\n",
       " 'my new doctor',\n",
       " ...]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d2bc5561",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "data_lem = pd.DataFrame(word_tri,columns=['data_tri'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4760298e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['easy', 'to', 'get']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_new = data_lem['data_tri'].values.tolist()\n",
    "data_words = list(sent_to_words(data_new))\n",
    "\n",
    "print(data_words[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "22fe55ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "203c4b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-9a736b398864>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Do lemmatization keeping only noun, adj, vb, adv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdata_lemmatized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlemmatization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_words_bigrams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallowed_postags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NOUN'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ADJ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'VERB'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ADV'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_lemmatized\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-a9dac53f8cd2>\u001b[0m in \u001b[0;36mlemmatization\u001b[1;34m(texts, allowed_postags)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mtexts_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mtexts_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemma_\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mallowed_postags\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtexts_out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1018\u001b[0m                 \u001b[0merror_handler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_error_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1020\u001b[1;33m                 \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1021\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1022\u001b[0m                 \u001b[1;31m# This typically happens if a component is not initialized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\pipeline\\tok2vec.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, docs)\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nO\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malloc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m         \u001b[0mtokvecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[0mbatch_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTok2VecListener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_batch_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlistener\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlisteners\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0monly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         \"\"\"\n\u001b[1;32m--> 315\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfinish_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\layers\\chain.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\layers\\chain.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\layers\\with_array.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, Xseq, is_train)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSeqT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeqT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXseq\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSeqT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXseq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRagged\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         return _ragged_forward(\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mRagged\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRagged\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRagged\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\layers\\with_array.py\u001b[0m in \u001b[0;36m_ragged_forward\u001b[1;34m(model, Xr, is_train)\u001b[0m\n\u001b[0;32m     87\u001b[0m ) -> Tuple[Ragged, Callable]:\n\u001b[0;32m     88\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mArrayXd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mArrayXd\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_dX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataXd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdYr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mRagged\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mRagged\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\layers\\chain.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\layers\\chain.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\layers\\maxout.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"W\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape2f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnO\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgemm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[0mY\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape1f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnO\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape3f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnO\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a789d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a30976",
   "metadata": {},
   "source": [
    "### After this implementation is left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7457ad95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a053212f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a6ff40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae25590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d8f5529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1)]\n"
     ]
    }
   ],
   "source": [
    "import gensim.corpora as corpora\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e3dc4dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=10, \n",
    "                                       random_state=100,\n",
    "                                       chunksize=100,\n",
    "                                       passes=10,\n",
    "                                       per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a48d571f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.094*\"staff\" + 0.094*\"doctor\" + 0.090*\"get\" + 0.090*\"see\" + '\n",
      "  '0.090*\"appointment\" + 0.090*\"able\" + 0.090*\"time\" + 0.090*\"friendly\" + '\n",
      "  '0.090*\"go\" + 0.090*\"easy\"'),\n",
      " (1,\n",
      "  '0.756*\"staff\" + 0.024*\"get\" + 0.024*\"doctor\" + 0.024*\"see\" + '\n",
      "  '0.024*\"appointment\" + 0.024*\"able\" + 0.024*\"friendly\" + 0.024*\"time\" + '\n",
      "  '0.024*\"easy\" + 0.024*\"go\"'),\n",
      " (2,\n",
      "  '0.677*\"appointment\" + 0.032*\"get\" + 0.032*\"staff\" + 0.032*\"doctor\" + '\n",
      "  '0.032*\"see\" + 0.032*\"able\" + 0.032*\"go\" + 0.032*\"time\" + 0.032*\"easy\" + '\n",
      "  '0.032*\"friendly\"'),\n",
      " (3,\n",
      "  '0.756*\"doctor\" + 0.024*\"get\" + 0.024*\"staff\" + 0.024*\"see\" + '\n",
      "  '0.024*\"appointment\" + 0.024*\"time\" + 0.024*\"friendly\" + 0.024*\"able\" + '\n",
      "  '0.024*\"go\" + 0.024*\"easy\"'),\n",
      " (4,\n",
      "  '0.094*\"get\" + 0.094*\"appointment\" + 0.094*\"doctor\" + 0.090*\"staff\" + '\n",
      "  '0.090*\"see\" + 0.090*\"time\" + 0.090*\"able\" + 0.090*\"friendly\" + 0.090*\"go\" + '\n",
      "  '0.090*\"easy\"'),\n",
      " (5,\n",
      "  '0.512*\"see\" + 0.268*\"go\" + 0.025*\"get\" + 0.024*\"doctor\" + 0.024*\"staff\" + '\n",
      "  '0.024*\"able\" + 0.024*\"appointment\" + 0.024*\"friendly\" + 0.024*\"time\" + '\n",
      "  '0.024*\"easy\"'),\n",
      " (6,\n",
      "  '0.629*\"get\" + 0.136*\"able\" + 0.136*\"easy\" + 0.012*\"appointment\" + '\n",
      "  '0.012*\"staff\" + 0.012*\"doctor\" + 0.012*\"see\" + 0.012*\"time\" + '\n",
      "  '0.012*\"friendly\" + 0.012*\"go\"'),\n",
      " (7,\n",
      "  '0.091*\"doctor\" + 0.091*\"get\" + 0.091*\"staff\" + 0.091*\"see\" + '\n",
      "  '0.091*\"appointment\" + 0.091*\"able\" + 0.091*\"time\" + 0.091*\"easy\" + '\n",
      "  '0.091*\"friendly\" + 0.091*\"go\"'),\n",
      " (8,\n",
      "  '0.354*\"friendly\" + 0.354*\"time\" + 0.034*\"staff\" + 0.032*\"get\" + '\n",
      "  '0.032*\"doctor\" + 0.032*\"see\" + 0.032*\"appointment\" + 0.032*\"able\" + '\n",
      "  '0.032*\"easy\" + 0.032*\"go\"'),\n",
      " (9,\n",
      "  '0.268*\"easy\" + 0.268*\"able\" + 0.268*\"schedule\" + 0.024*\"doctor\" + '\n",
      "  '0.024*\"get\" + 0.024*\"staff\" + 0.024*\"see\" + 0.024*\"appointment\" + '\n",
      "  '0.024*\"go\" + 0.024*\"friendly\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bfa0da35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score:  0.7161455246794652\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d0090127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "<>:8: DeprecationWarning: invalid escape sequence \\-\n",
      "<>:8: DeprecationWarning: invalid escape sequence \\-\n",
      "<ipython-input-65-d4570a94d7d3>:8: DeprecationWarning: invalid escape sequence \\-\n",
      "  token_pattern='[a-zA-Z\\-][a-zA-Z\\-]{2,}')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-d4570a94d7d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                              \u001b[0mstop_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlowercase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                              token_pattern='[a-zA-Z\\-][a-zA-Z\\-]{2,}')\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdata_vectorized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_lemmatized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Build a Latent Dirichlet Allocation Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1328\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1330\u001b[1;33m         \u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1332\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1199\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1201\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1202\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1203\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \"\"\"\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    " \n",
    "NUM_TOPICS = 4\n",
    " \n",
    "vectorizer = CountVectorizer(min_df=5, max_df=0.9, \n",
    "                             stop_words='english', lowercase=True, \n",
    "                             token_pattern='[a-zA-Z\\-][a-zA-Z\\-]{2,}')\n",
    "data_vectorized = vectorizer.fit_transform(data_lemmatized)\n",
    " \n",
    "# Build a Latent Dirichlet Allocation Model\n",
    "lda_model = LatentDirichletAllocation(max_iter=10, learning_method='online',evaluate_every=3)\n",
    "lda_Z = lda_model.fit_transform(data_vectorized)\n",
    " \n",
    "text = \"The economy is working better than ever\"\n",
    "x = lda_model.transform(vectorizer.transform([text]))[0]\n",
    "print(x, x.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a68a34b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "Vocabulary not fitted or provided",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-c9fd8890da71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msklearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpanel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_vectorized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tsne'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpanel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyLDAvis\\sklearn.py\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(lda_model, dtm, vectorizer, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[0mSee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \"\"\"\n\u001b[1;32m---> 94\u001b[1;33m     \u001b[0mopts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_extract_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyLDAvis\\sklearn.py\u001b[0m in \u001b[0;36m_extract_data\u001b[1;34m(lda_model, dtm, vectorizer)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_extract_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mvocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mdoc_lengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_doc_lengths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mterm_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_term_freqs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyLDAvis\\sklearn.py\u001b[0m in \u001b[0;36m_get_vocab\u001b[1;34m(vectorizer)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_get_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFutureWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mget_feature_names\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1427\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m         \"\"\"\n\u001b[1;32m-> 1429\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1431\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_check_vocabulary\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Vocabulary not fitted or provided\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: Vocabulary not fitted or provided"
     ]
    }
   ],
   "source": [
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "panel = pyLDAvis.sklearn.prepare(lda_model, data_vectorized, vectorizer, mds='tsne')\n",
    "panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd845e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
